{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a65c63f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_ok\n"
     ]
    }
   ],
   "source": [
    "print(\"all_ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de80b62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6aa2bdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4515cdf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05e3bc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=ChatGroq(model=\"deepseek-r1-distill-llama-70b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ffaaf4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "print(llm.invoke(\"What is the capital of France?\").content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df5c2e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6adec1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model=GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcacd34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_vector=embedding_model.embed_query(\"What is the capital of France?\")\n",
    "#len(doc_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792ae86b",
   "metadata": {},
   "source": [
    "## 1. Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff8dcbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8feb528d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68999868",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f32486a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\LLMOpsPractice\\\\Documentportal\\\\notebook'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0253c52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path=os.path.join(os.getcwd(), \"data\", \"sample.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e9d58b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader=PyPDFLoader(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd2ae1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents=loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "376cb8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6670c7ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bc6e89",
   "metadata": {},
   "source": [
    "### this is a experimental thing there is no deterministic way to split the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2e5f06d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter=RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=150,\n",
    "    length_function=len\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "361efa05",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs=text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "53ed226c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "765"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5f15a31e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'e:\\\\LLMOpsPractice\\\\Documentportal\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 0, 'page_label': '1'}, page_content='Llama 2: Open Foundation and Fine-Tuned Chat Models\\nHugo Touvron∗ Louis Martin† Kevin Stone†\\nPeter Albert Amjad Almahairi Yasmine Babaei Nikolay Bashlykov Soumya Batra\\nPrajjwal Bhargava Shruti Bhosale Dan Bikel Lukas Blecher Cristian Canton Ferrer Moya Chen\\nGuillem Cucurull David Esiobu Jude Fernandes Jeremy Fu Wenyin Fu Brian Fuller\\nCynthia Gao Vedanuj Goswami Naman Goyal Anthony Hartshorn Saghar Hosseini Rui Hou\\nHakan Inan Marcin Kardas Viktor Kerkez Madian Khabsa Isabel Kloumann Artem Korenev')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "72cddd95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'producer': 'pdfTeX-1.40.25',\n",
       " 'creator': 'LaTeX with hyperref',\n",
       " 'creationdate': '2023-07-20T00:30:36+00:00',\n",
       " 'author': '',\n",
       " 'keywords': '',\n",
       " 'moddate': '2023-07-20T00:30:36+00:00',\n",
       " 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5',\n",
       " 'subject': '',\n",
       " 'title': '',\n",
       " 'trapped': '/False',\n",
       " 'source': 'e:\\\\LLMOpsPractice\\\\Documentportal\\\\notebook\\\\data\\\\sample.pdf',\n",
       " 'total_pages': 77,\n",
       " 'page': 0,\n",
       " 'page_label': '1'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ce96aa5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'producer': 'pdfTeX-1.40.25',\n",
       " 'creator': 'LaTeX with hyperref',\n",
       " 'creationdate': '2023-07-20T00:30:36+00:00',\n",
       " 'author': '',\n",
       " 'keywords': '',\n",
       " 'moddate': '2023-07-20T00:30:36+00:00',\n",
       " 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5',\n",
       " 'subject': '',\n",
       " 'title': '',\n",
       " 'trapped': '/False',\n",
       " 'source': 'e:\\\\LLMOpsPractice\\\\Documentportal\\\\notebook\\\\data\\\\sample.pdf',\n",
       " 'total_pages': 77,\n",
       " 'page': 0,\n",
       " 'page_label': '1'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[1].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "96181a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#0,1,2,3\n",
    "#page_lable=4\n",
    "#actual page is 4 \n",
    "\n",
    "#page_index=3\n",
    "#page_lable=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "865ed5e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'producer': 'pdfTeX-1.40.25',\n",
       " 'creator': 'LaTeX with hyperref',\n",
       " 'creationdate': '2023-07-20T00:30:36+00:00',\n",
       " 'author': '',\n",
       " 'keywords': '',\n",
       " 'moddate': '2023-07-20T00:30:36+00:00',\n",
       " 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5',\n",
       " 'subject': '',\n",
       " 'title': '',\n",
       " 'trapped': '/False',\n",
       " 'source': 'e:\\\\LLMOpsPractice\\\\Documentportal\\\\notebook\\\\data\\\\sample.pdf',\n",
       " 'total_pages': 77,\n",
       " 'page': 10,\n",
       " 'page_label': '11'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[100].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3fd5afde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'producer': 'pdfTeX-1.40.25',\n",
       " 'creator': 'LaTeX with hyperref',\n",
       " 'creationdate': '2023-07-20T00:30:36+00:00',\n",
       " 'author': '',\n",
       " 'keywords': '',\n",
       " 'moddate': '2023-07-20T00:30:36+00:00',\n",
       " 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5',\n",
       " 'subject': '',\n",
       " 'title': '',\n",
       " 'trapped': '/False',\n",
       " 'source': 'e:\\\\LLMOpsPractice\\\\Documentportal\\\\notebook\\\\data\\\\sample.pdf',\n",
       " 'total_pages': 77,\n",
       " 'page': 20,\n",
       " 'page_label': '21'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[200].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ec192b03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Llama 2: Open Foundation and Fine-Tuned Chat Models\\nHugo Touvron∗ Louis Martin† Kevin Stone†\\nPeter Albert Amjad Almahairi Yasmine Babaei Nikolay Bashlykov Soumya Batra\\nPrajjwal Bhargava Shruti Bhosale Dan Bikel Lukas Blecher Cristian Canton Ferrer Moya Chen\\nGuillem Cucurull David Esiobu Jude Fernandes Jeremy Fu Wenyin Fu Brian Fuller\\nCynthia Gao Vedanuj Goswami Naman Goyal Anthony Hartshorn Saghar Hosseini Rui Hou\\nHakan Inan Marcin Kardas Viktor Kerkez Madian Khabsa Isabel Kloumann Artem Korenev'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f92af725",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9ded599c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Llama 2: Open Foundation and Fine-Tuned Chat Models\\nHugo Touvron∗ Louis Martin† Kevin Stone†\\nPeter Albert Amjad Almahairi Yasmine Babaei Nikolay Bashlykov Soumya Batra\\nPrajjwal Bhargava Shruti Bhosale Dan Bikel Lukas Blecher Cristian Canton Ferrer Moya Chen\\nGuillem Cucurull David Esiobu Jude Fernandes Jeremy Fu Wenyin Fu Brian Fuller\\nCynthia Gao Vedanuj Goswami Naman Goyal Anthony Hartshorn Saghar Hosseini Rui Hou\\nHakan Inan Marcin Kardas Viktor Kerkez Madian Khabsa Isabel Kloumann Artem Korenev'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6835d49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_vector=embedding_model.embed_documents(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2c109387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedding_model.embed_documents(docs[0].page_content)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ed952e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore=FAISS.from_documents(docs, embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1487e254",
   "metadata": {},
   "outputs": [],
   "source": [
    "#token->words\n",
    "\n",
    "#chunk--> it is collection of words(token)[characters]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e769025",
   "metadata": {},
   "source": [
    "1. in memory(faiss is in memory vector store,chroma)\n",
    "2. on disk storage(faiss you can persist over the disk,chroma)\n",
    "3. cloud storage(cloud variant of faiss is not available)(pinecone,weaviate,milvus,mongodbvectorsearch,astradb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decd5d79",
   "metadata": {},
   "source": [
    "## This is a Retrieval proceesss\n",
    "\n",
    "means from the vectordatabase we are going to fetch or retrive or rank the most appropriate k result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "55503be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_doc=vectorstore.similarity_search(\"llama2 finetuning benchmark experiments.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "da52627f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='e471c2f5-bc8a-4beb-b7dc-f746b25ec807', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'e:\\\\LLMOpsPractice\\\\Documentportal\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 7, 'page_label': '8'}, page_content='13B 18.9 66.1 52.6 62.3 10.9 46.9 37.0 33.9\\n33B 26.0 70.0 58.4 67.6 21.4 57.8 39.8 41.7\\n65B 30.7 70.7 60.5 68.6 30.8 63.4 43.5 47.6\\nLlama 2\\n7B 16.8 63.9 48.9 61.3 14.6 45.3 32.6 29.3\\n13B 24.5 66.9 55.4 65.8 28.7 54.8 39.4 39.1\\n34B 27.8 69.9 58.7 68.0 24.2 62.6 44.1 43.4\\n70B 37.5 71.9 63.6 69.4 35.2 68.9 51.2 54.2\\nTable 3: Overall performance on grouped academic benchmarks compared to open-source base models.'),\n",
       " Document(id='207e1bc5-aa1b-43c3-8f6c-29bd43a9b700', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'e:\\\\LLMOpsPractice\\\\Documentportal\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 73, 'page_label': '74'}, page_content='Llama 2\\n7B 0.28 0.25 0.29 0.50 0.36 0.37 0.21 0.34 0.32 0.50 0.28 0.19 0.26 0.32 0.44 0.51 0.30 0.2513B 0.24 0.25 0.35 0.50 0.41 0.36 0.24 0.39 0.35 0.48 0.31 0.18 0.27 0.34 0.46 0.66 0.35 0.2834B 0.27 0.24 0.33 0.56 0.41 0.36 0.26 0.32 0.36 0.53 0.33 0.07 0.26 0.30 0.45 0.56 0.26 0.3570B 0.31 0.29 0.35 0.51 0.41 0.45 0.27 0.34 0.40 0.52 0.36 0.12 0.28 0.31 0.45 0.65 0.33 0.20\\nFine-tuned'),\n",
       " Document(id='b6a93639-5901-4d7e-b115-d25769880afc', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'e:\\\\LLMOpsPractice\\\\Documentportal\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 70, 'page_label': '71'}, page_content='65B 14.27 31.59 21.90 14.89 23.51 22.27 17.16 18.91 28.40 19.32 28.71 22.00 20.03\\nLlama 2\\n7B 16.53 31.15 22.63 15.74 26.87 19.95 15.79 19.55 25.03 18.92 21.53 22.34 20.20\\n13B 21.29 37.25 22.81 17.77 32.65 24.13 21.05 20.19 35.40 27.69 26.99 28.26 23.84\\n34B 16.76 29.63 23.36 14.38 27.43 19.49 18.54 17.31 26.38 18.73 22.78 21.66 19.04\\n70B 21.29 32.90 25.91 16.92 30.60 21.35 16.93 21.47 30.42 20.12 31.05 28.43 22.35\\nFine-tuned\\nChatGPT 0.23 0.22 0.18 0 0.19 0 0.46 0 0.13 0 0.47 0 0.66'),\n",
       " Document(id='367a2c79-8876-4efb-9500-02f61f47e7a0', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'e:\\\\LLMOpsPractice\\\\Documentportal\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 6, 'page_label': '7'}, page_content='models internally. For these models, we always pick the best score between our evaluation framework and\\nany publicly reported results.\\nIn Table 3, we summarize the overall performance across a suite of popular benchmarks. Note that safety\\nbenchmarks are shared in Section 4.1. The benchmarks are grouped into the categories listed below. The\\nresults for all the individual benchmarks are available in Section A.2.2.')]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b59e667e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'13B 18.9 66.1 52.6 62.3 10.9 46.9 37.0 33.9\\n33B 26.0 70.0 58.4 67.6 21.4 57.8 39.8 41.7\\n65B 30.7 70.7 60.5 68.6 30.8 63.4 43.5 47.6\\nLlama 2\\n7B 16.8 63.9 48.9 61.3 14.6 45.3 32.6 29.3\\n13B 24.5 66.9 55.4 65.8 28.7 54.8 39.4 39.1\\n34B 27.8 69.9 58.7 68.0 24.2 62.6 44.1 43.4\\n70B 37.5 71.9 63.6 69.4 35.2 68.9 51.2 54.2\\nTable 3: Overall performance on grouped academic benchmarks compared to open-source base models.'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_doc[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8d2f345b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Llama 2\\n7B 0.28 0.25 0.29 0.50 0.36 0.37 0.21 0.34 0.32 0.50 0.28 0.19 0.26 0.32 0.44 0.51 0.30 0.2513B 0.24 0.25 0.35 0.50 0.41 0.36 0.24 0.39 0.35 0.48 0.31 0.18 0.27 0.34 0.46 0.66 0.35 0.2834B 0.27 0.24 0.33 0.56 0.41 0.36 0.26 0.32 0.36 0.53 0.33 0.07 0.26 0.30 0.45 0.56 0.26 0.3570B 0.31 0.29 0.35 0.51 0.41 0.45 0.27 0.34 0.40 0.52 0.36 0.12 0.28 0.31 0.45 0.65 0.33 0.20\\nFine-tuned'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_doc[1].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4c52e60d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'65B 14.27 31.59 21.90 14.89 23.51 22.27 17.16 18.91 28.40 19.32 28.71 22.00 20.03\\nLlama 2\\n7B 16.53 31.15 22.63 15.74 26.87 19.95 15.79 19.55 25.03 18.92 21.53 22.34 20.20\\n13B 21.29 37.25 22.81 17.77 32.65 24.13 21.05 20.19 35.40 27.69 26.99 28.26 23.84\\n34B 16.76 29.63 23.36 14.38 27.43 19.49 18.54 17.31 26.38 18.73 22.78 21.66 19.04\\n70B 21.29 32.90 25.91 16.92 30.60 21.35 16.93 21.47 30.42 20.12 31.05 28.43 22.35\\nFine-tuned\\nChatGPT 0.23 0.22 0.18 0 0.19 0 0.46 0 0.13 0 0.47 0 0.66'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_doc[2].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "01f6ff55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'models internally. For these models, we always pick the best score between our evaluation framework and\\nany publicly reported results.\\nIn Table 3, we summarize the overall performance across a suite of popular benchmarks. Note that safety\\nbenchmarks are shared in Section 4.1. The benchmarks are grouped into the categories listed below. The\\nresults for all the individual benchmarks are available in Section A.2.2.'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_doc[3].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6a971b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_doc=vectorstore.similarity_search(\"llama2 finetuning benchmark experiments.\",k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b687780f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='e471c2f5-bc8a-4beb-b7dc-f746b25ec807', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'e:\\\\LLMOpsPractice\\\\Documentportal\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 7, 'page_label': '8'}, page_content='13B 18.9 66.1 52.6 62.3 10.9 46.9 37.0 33.9\\n33B 26.0 70.0 58.4 67.6 21.4 57.8 39.8 41.7\\n65B 30.7 70.7 60.5 68.6 30.8 63.4 43.5 47.6\\nLlama 2\\n7B 16.8 63.9 48.9 61.3 14.6 45.3 32.6 29.3\\n13B 24.5 66.9 55.4 65.8 28.7 54.8 39.4 39.1\\n34B 27.8 69.9 58.7 68.0 24.2 62.6 44.1 43.4\\n70B 37.5 71.9 63.6 69.4 35.2 68.9 51.2 54.2\\nTable 3: Overall performance on grouped academic benchmarks compared to open-source base models.'),\n",
       " Document(id='207e1bc5-aa1b-43c3-8f6c-29bd43a9b700', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'e:\\\\LLMOpsPractice\\\\Documentportal\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 73, 'page_label': '74'}, page_content='Llama 2\\n7B 0.28 0.25 0.29 0.50 0.36 0.37 0.21 0.34 0.32 0.50 0.28 0.19 0.26 0.32 0.44 0.51 0.30 0.2513B 0.24 0.25 0.35 0.50 0.41 0.36 0.24 0.39 0.35 0.48 0.31 0.18 0.27 0.34 0.46 0.66 0.35 0.2834B 0.27 0.24 0.33 0.56 0.41 0.36 0.26 0.32 0.36 0.53 0.33 0.07 0.26 0.30 0.45 0.56 0.26 0.3570B 0.31 0.29 0.35 0.51 0.41 0.45 0.27 0.34 0.40 0.52 0.36 0.12 0.28 0.31 0.45 0.65 0.33 0.20\\nFine-tuned'),\n",
       " Document(id='b6a93639-5901-4d7e-b115-d25769880afc', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'e:\\\\LLMOpsPractice\\\\Documentportal\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 70, 'page_label': '71'}, page_content='65B 14.27 31.59 21.90 14.89 23.51 22.27 17.16 18.91 28.40 19.32 28.71 22.00 20.03\\nLlama 2\\n7B 16.53 31.15 22.63 15.74 26.87 19.95 15.79 19.55 25.03 18.92 21.53 22.34 20.20\\n13B 21.29 37.25 22.81 17.77 32.65 24.13 21.05 20.19 35.40 27.69 26.99 28.26 23.84\\n34B 16.76 29.63 23.36 14.38 27.43 19.49 18.54 17.31 26.38 18.73 22.78 21.66 19.04\\n70B 21.29 32.90 25.91 16.92 30.60 21.35 16.93 21.47 30.42 20.12 31.05 28.43 22.35\\nFine-tuned\\nChatGPT 0.23 0.22 0.18 0 0.19 0 0.46 0 0.13 0 0.47 0 0.66'),\n",
       " Document(id='367a2c79-8876-4efb-9500-02f61f47e7a0', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'e:\\\\LLMOpsPractice\\\\Documentportal\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 6, 'page_label': '7'}, page_content='models internally. For these models, we always pick the best score between our evaluation framework and\\nany publicly reported results.\\nIn Table 3, we summarize the overall performance across a suite of popular benchmarks. Note that safety\\nbenchmarks are shared in Section 4.1. The benchmarks are grouped into the categories listed below. The\\nresults for all the individual benchmarks are available in Section A.2.2.'),\n",
       " Document(id='048aba6b-872c-460e-b504-367614f2d966', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'e:\\\\LLMOpsPractice\\\\Documentportal\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 75, 'page_label': '76'}, page_content='small delta (-0.9) between the \"clean\" subset performance and the sampling mean. No other dataset (for any\\nchoice ofL) appears to have benefitted from dataset contamination, and we omit results from these datasets\\nfor conciseness.\\n76'),\n",
       " Document(id='0fb41216-fafb-4237-b6de-18254675bed4', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'e:\\\\LLMOpsPractice\\\\Documentportal\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 48, 'page_label': '49'}, page_content='Human-Eval and MBPP respectively. For pass@100 and pass@80 scores, we use a temperature of 0.8 and\\ntop-p=0.95. For pass@1 scores, we use a temperature of 0.1 and top-p=0.95.\\n49'),\n",
       " Document(id='7ba6da88-be52-4eac-9a21-e309a1167a32', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'e:\\\\LLMOpsPractice\\\\Documentportal\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 1, 'page_label': '2'}, page_content='Contents\\n1 Introduction 3\\n2 Pretraining 5\\n2.1 Pretraining Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\\n2.2 Training Details . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\\n2.3 Llama 2Pretrained Model Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\\n3 Fine-tuning 8\\n3.1 Supervised Fine-Tuning (SFT) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9'),\n",
       " Document(id='ce15fe9e-71eb-46a7-b169-5ce36b5fa451', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'e:\\\\LLMOpsPractice\\\\Documentportal\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 73, 'page_label': '74'}, page_content='Llama 1\\n7B 0.27 0.26 0.34 0.54 0.36 0.39 0.26 0.28 0.33 0.45 0.33 0.17 0.24 0.31 0.44 0.57 0.39 0.3513B 0.24 0.24 0.31 0.52 0.37 0.37 0.23 0.28 0.31 0.50 0.27 0.10 0.24 0.27 0.41 0.55 0.34 0.2533B 0.23 0.26 0.34 0.50 0.36 0.35 0.24 0.33 0.34 0.49 0.31 0.12 0.23 0.30 0.41 0.60 0.28 0.2765B 0.25 0.26 0.34 0.46 0.36 0.40 0.25 0.32 0.32 0.48 0.31 0.11 0.25 0.30 0.43 0.60 0.39 0.34\\nLlama 2'),\n",
       " Document(id='2eff307a-6761-4bd7-99ab-899805565d68', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'e:\\\\LLMOpsPractice\\\\Documentportal\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 72, 'page_label': '73'}, page_content='Llama 2\\n7B 0.15 0.30 0.12 0.35 0.25 0.43 0.18 0.38 0.16 0.12 0.29 -0.1313B 0.14 0.35 0.23 0.29 0.23 0.57 0.20 0.52 0.22 0.12 0.29 -0.1734B 0.12 0.16 0.18 0.36 0.35 0.52 0.10 0.54 0.28 0.11 0.30 -0.1970B 0.16 0.21 0.17 0.35 0.30 0.60 0.18 0.67 0.26 0.12 0.30 -0.10\\nFine-tuned\\nChatGPT 0.15 0.22 0.05 0.24 0.31 0.35 0.09 0.42 0.19 0.09 0.23 0.06MPT-instruct 7B 0.13 0.29 0.12 0.34 0.35 0.53 0.28 0.56 0.27 0.02 0.32 -0.12Falcon-instruct 7B 0.11 0.21 0.21 0.28 0.34 0.23 0.31 0.45 0.23 0.22 0.29 -0.27'),\n",
       " Document(id='0893fd18-b760-4fc7-8a85-f5d906c1bf30', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'e:\\\\LLMOpsPractice\\\\Documentportal\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 2, 'page_label': '3'}, page_content='be on par with some of the closed-source models, at least on the human evaluations we performed (see\\nFigures 1 and 3). We have taken measures to increase the safety of these models, using safety-specific data\\nannotation and tuning, as well as conducting red-teaming and employing iterative evaluations. Additionally,\\nthis paper contributes a thorough description of our fine-tuning methodology and approach to improving')]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "67ff01f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_doc=vectorstore.similarity_search(\"llama2 finetuning benchmark experiments.\",k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c2c9f69f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='e471c2f5-bc8a-4beb-b7dc-f746b25ec807', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'e:\\\\LLMOpsPractice\\\\Documentportal\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 7, 'page_label': '8'}, page_content='13B 18.9 66.1 52.6 62.3 10.9 46.9 37.0 33.9\\n33B 26.0 70.0 58.4 67.6 21.4 57.8 39.8 41.7\\n65B 30.7 70.7 60.5 68.6 30.8 63.4 43.5 47.6\\nLlama 2\\n7B 16.8 63.9 48.9 61.3 14.6 45.3 32.6 29.3\\n13B 24.5 66.9 55.4 65.8 28.7 54.8 39.4 39.1\\n34B 27.8 69.9 58.7 68.0 24.2 62.6 44.1 43.4\\n70B 37.5 71.9 63.6 69.4 35.2 68.9 51.2 54.2\\nTable 3: Overall performance on grouped academic benchmarks compared to open-source base models.')]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c39292e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retriever=vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc8481a",
   "metadata": {},
   "source": [
    "### you can explore about keyword filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2df7b858",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4d5f07ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='e471c2f5-bc8a-4beb-b7dc-f746b25ec807', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'e:\\\\LLMOpsPractice\\\\Documentportal\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 7, 'page_label': '8'}, page_content='13B 18.9 66.1 52.6 62.3 10.9 46.9 37.0 33.9\\n33B 26.0 70.0 58.4 67.6 21.4 57.8 39.8 41.7\\n65B 30.7 70.7 60.5 68.6 30.8 63.4 43.5 47.6\\nLlama 2\\n7B 16.8 63.9 48.9 61.3 14.6 45.3 32.6 29.3\\n13B 24.5 66.9 55.4 65.8 28.7 54.8 39.4 39.1\\n34B 27.8 69.9 58.7 68.0 24.2 62.6 44.1 43.4\\n70B 37.5 71.9 63.6 69.4 35.2 68.9 51.2 54.2\\nTable 3: Overall performance on grouped academic benchmarks compared to open-source base models.'),\n",
       " Document(id='207e1bc5-aa1b-43c3-8f6c-29bd43a9b700', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'e:\\\\LLMOpsPractice\\\\Documentportal\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 73, 'page_label': '74'}, page_content='Llama 2\\n7B 0.28 0.25 0.29 0.50 0.36 0.37 0.21 0.34 0.32 0.50 0.28 0.19 0.26 0.32 0.44 0.51 0.30 0.2513B 0.24 0.25 0.35 0.50 0.41 0.36 0.24 0.39 0.35 0.48 0.31 0.18 0.27 0.34 0.46 0.66 0.35 0.2834B 0.27 0.24 0.33 0.56 0.41 0.36 0.26 0.32 0.36 0.53 0.33 0.07 0.26 0.30 0.45 0.56 0.26 0.3570B 0.31 0.29 0.35 0.51 0.41 0.45 0.27 0.34 0.40 0.52 0.36 0.12 0.28 0.31 0.45 0.65 0.33 0.20\\nFine-tuned'),\n",
       " Document(id='b6a93639-5901-4d7e-b115-d25769880afc', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'e:\\\\LLMOpsPractice\\\\Documentportal\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 70, 'page_label': '71'}, page_content='65B 14.27 31.59 21.90 14.89 23.51 22.27 17.16 18.91 28.40 19.32 28.71 22.00 20.03\\nLlama 2\\n7B 16.53 31.15 22.63 15.74 26.87 19.95 15.79 19.55 25.03 18.92 21.53 22.34 20.20\\n13B 21.29 37.25 22.81 17.77 32.65 24.13 21.05 20.19 35.40 27.69 26.99 28.26 23.84\\n34B 16.76 29.63 23.36 14.38 27.43 19.49 18.54 17.31 26.38 18.73 22.78 21.66 19.04\\n70B 21.29 32.90 25.91 16.92 30.60 21.35 16.93 21.47 30.42 20.12 31.05 28.43 22.35\\nFine-tuned\\nChatGPT 0.23 0.22 0.18 0 0.19 0 0.46 0 0.13 0 0.47 0 0.66'),\n",
       " Document(id='367a2c79-8876-4efb-9500-02f61f47e7a0', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'e:\\\\LLMOpsPractice\\\\Documentportal\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 6, 'page_label': '7'}, page_content='models internally. For these models, we always pick the best score between our evaluation framework and\\nany publicly reported results.\\nIn Table 3, we summarize the overall performance across a suite of popular benchmarks. Note that safety\\nbenchmarks are shared in Section 4.1. The benchmarks are grouped into the categories listed below. The\\nresults for all the individual benchmarks are available in Section A.2.2.'),\n",
       " Document(id='048aba6b-872c-460e-b504-367614f2d966', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'e:\\\\LLMOpsPractice\\\\Documentportal\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 75, 'page_label': '76'}, page_content='small delta (-0.9) between the \"clean\" subset performance and the sampling mean. No other dataset (for any\\nchoice ofL) appears to have benefitted from dataset contamination, and we omit results from these datasets\\nfor conciseness.\\n76'),\n",
       " Document(id='0fb41216-fafb-4237-b6de-18254675bed4', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'e:\\\\LLMOpsPractice\\\\Documentportal\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 48, 'page_label': '49'}, page_content='Human-Eval and MBPP respectively. For pass@100 and pass@80 scores, we use a temperature of 0.8 and\\ntop-p=0.95. For pass@1 scores, we use a temperature of 0.1 and top-p=0.95.\\n49'),\n",
       " Document(id='7ba6da88-be52-4eac-9a21-e309a1167a32', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'e:\\\\LLMOpsPractice\\\\Documentportal\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 1, 'page_label': '2'}, page_content='Contents\\n1 Introduction 3\\n2 Pretraining 5\\n2.1 Pretraining Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\\n2.2 Training Details . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\\n2.3 Llama 2Pretrained Model Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\\n3 Fine-tuning 8\\n3.1 Supervised Fine-Tuning (SFT) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9'),\n",
       " Document(id='ce15fe9e-71eb-46a7-b169-5ce36b5fa451', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'e:\\\\LLMOpsPractice\\\\Documentportal\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 73, 'page_label': '74'}, page_content='Llama 1\\n7B 0.27 0.26 0.34 0.54 0.36 0.39 0.26 0.28 0.33 0.45 0.33 0.17 0.24 0.31 0.44 0.57 0.39 0.3513B 0.24 0.24 0.31 0.52 0.37 0.37 0.23 0.28 0.31 0.50 0.27 0.10 0.24 0.27 0.41 0.55 0.34 0.2533B 0.23 0.26 0.34 0.50 0.36 0.35 0.24 0.33 0.34 0.49 0.31 0.12 0.23 0.30 0.41 0.60 0.28 0.2765B 0.25 0.26 0.34 0.46 0.36 0.40 0.25 0.32 0.32 0.48 0.31 0.11 0.25 0.30 0.43 0.60 0.39 0.34\\nLlama 2'),\n",
       " Document(id='2eff307a-6761-4bd7-99ab-899805565d68', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'e:\\\\LLMOpsPractice\\\\Documentportal\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 72, 'page_label': '73'}, page_content='Llama 2\\n7B 0.15 0.30 0.12 0.35 0.25 0.43 0.18 0.38 0.16 0.12 0.29 -0.1313B 0.14 0.35 0.23 0.29 0.23 0.57 0.20 0.52 0.22 0.12 0.29 -0.1734B 0.12 0.16 0.18 0.36 0.35 0.52 0.10 0.54 0.28 0.11 0.30 -0.1970B 0.16 0.21 0.17 0.35 0.30 0.60 0.18 0.67 0.26 0.12 0.30 -0.10\\nFine-tuned\\nChatGPT 0.15 0.22 0.05 0.24 0.31 0.35 0.09 0.42 0.19 0.09 0.23 0.06MPT-instruct 7B 0.13 0.29 0.12 0.34 0.35 0.53 0.28 0.56 0.27 0.02 0.32 -0.12Falcon-instruct 7B 0.11 0.21 0.21 0.28 0.34 0.23 0.31 0.45 0.23 0.22 0.29 -0.27'),\n",
       " Document(id='0893fd18-b760-4fc7-8a85-f5d906c1bf30', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'e:\\\\LLMOpsPractice\\\\Documentportal\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 2, 'page_label': '3'}, page_content='be on par with some of the closed-source models, at least on the human evaluations we performed (see\\nFigures 1 and 3). We have taken measures to increase the safety of these models, using safety-specific data\\nannotation and tuning, as well as conducting red-teaming and employing iterative evaluations. Additionally,\\nthis paper contributes a thorough description of our fine-tuning methodology and approach to improving')]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"llama2 finetuning benchmark experiments.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5a2e3a",
   "metadata": {},
   "source": [
    "## Question: user question\n",
    "## Context: based on the question retrieving the info from the vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "32650c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "        Answer the question based on the context provided below. \n",
    "        If the context does not contain sufficient information, respond with: \n",
    "        \"I do not have enough information about this.\"\n",
    "\n",
    "        Context: {context}\n",
    "\n",
    "        Question: {question}\n",
    "\n",
    "        Answer:\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9189656c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ccc6ccf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=PromptTemplate(\n",
    "    template=prompt_template,\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "82058939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template='\\n        Answer the question based on the context provided below. \\n        If the context does not contain sufficient information, respond with: \\n        \"I do not have enough information about this.\"\\n\\n        Context: {context}\\n\\n        Question: {question}\\n\\n        Answer:')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45dc8fe",
   "metadata": {},
   "source": [
    "PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template='\\n        Answer the question based on the context provided below. \\n        If the context does not contain sufficient information, respond with: \\n        \"I do not have enough information about this.\"\\n\\n        Context: {context}\\n\\n        Question: {question}\\n\\n        Answer:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d5b39444",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f17d8d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser=StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3ef826e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join([doc.page_content for doc in docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fbcf20aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b10cb466",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0c3976d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<think>\\nAlright, I need to answer the question about the Llama 2 fine-tuning benchmark experiments based on the provided context. Let me go through the context step by step.\\n\\nFirst, I see multiple tables and sections mentioning \"Llama 2\" and \"Fine-tuned\" models. Table 3 lists various benchmarks for models including Llama 2 in different sizes (7B, 13B, 34B, 70B). The table has a lot of numbers, but the categories aren\\'t clearly labeled, so it\\'s a bit confusing. However, it does mention that the results are part of grouped academic benchmarks, so these are likely performance metrics.\\n\\nNext, there\\'s another section with fine-tuned models, including ChatGPT, MPT-instruct, Falcon-instruct, and Llama 2-Chat variants. This table has columns like % (true + info), % true, and % info. These might be accuracy metrics or similar performance indicators. For example, ChatGPT has 78.46, 79.92, and 98.53 in these categories. Llama 2-Chat models also have their own numbers here.\\n\\nLooking further, there\\'s a mention of ablation experiments and hyperparameters, but the user didn\\'t ask about that specifically. However, these details might be part of the fine-tuning process. The hyperparameters include AdamW optimizer settings, learning rate schedules, weight decay, and gradient clipping, which are important for model training.\\n\\nIn the section labeled \"A.2.2 Additional Details for Pretrained Models Evaluation,\" there\\'s a mention of MMLU evaluation for Llama 2 models and other open-source models. This suggests that the fine-tuning might have included evaluations on specific datasets or metrics like MMLU.\\n\\nAnother part talks about changes made during pretraining, such as data cleaning, updated data mixes, increased training tokens, doubled context length, and the use of grouped-query attention. While this is about pretraining, these improvements could affect fine-tuning performance.\\n\\nI should also check if there\\'s any direct mention of the experiments conducted during fine-tuning. The context mentions that for these models, the best scores between their evaluation framework and publicly reported results are chosen. This indicates a thorough evaluation process.\\n\\nPutting it all together, the context provides information on the performance of fine-tuned Llama 2 models across various benchmarks, including specific metrics and the evaluation process. It also touches on the training parameters that might influence fine-tuning effectiveness.\\n\\nHowever, the context is somewhat fragmented. While I can gather that fine-tuning involved various benchmark tests and that the models showed improved performance, the details about the specific experiments (like what tasks were fine-tuned, how they were conducted, etc.) are not explicitly stated. The numbers provided are results, but without more context on the experiments themselves, it\\'s challenging to describe the experiments in detail.\\n\\nTherefore, while there\\'s information about the outcomes of fine-tuning, the question is about the experiments themselves. Since the context doesn\\'t provide a detailed description of the experiments beyond mentioning benchmark performance and some training parameters, I might not have enough information to fully answer the question.\\n</think>\\n\\nI do not have enough information about this.'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"tell  me about the llama2 finetuning benchmark experiments?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ca813139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<think>\\nOkay, I need to answer the question about the scaling trends for the reward model based on the provided context. Let me read through the context carefully to find relevant information.\\n\\nThe context mentions Figure 6, which reports trends showing that larger models achieve higher performance with a similar volume of data. It also states that the scaling performance hasn't plateaued yet, indicating there's room for improvement with more data annotations. This suggests that as the model size increases, the reward model's performance improves, and they haven't reached the limit yet.\\n\\nI should check if there's any other information about scaling trends. There's a mention of Figure 29, which correlates reward model scores with human ratings, but that's more about calibration than scaling. The training objectives and loss functions are discussed, but they don't directly address scaling trends.\\n\\nSo, the key points are from Figure 6: larger models perform better, and scaling hasn't plateaued, meaning more data could lead to further improvements.\\n</think>\\n\\nThe scaling trends for the reward model, as indicated by Figure 6, show that larger models achieve higher performance with a similar amount of data. Importantly, the scaling performance has not yet plateaued, suggesting that there is potential for further improvement as more data annotations are added. This implies that increasing model size and data volume can lead to enhanced reward model performance.\""
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"can you tell me Scaling trends for the reward model?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3cc144e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from utils.model_loader import ModelLoader\n",
    "#loader=ModelLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "07b165f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm =ChatGroq(model=\"qwen/qwen3-32b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "be8572e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_groq import ChatGroq\n",
    "# from langchain.callbacks import get_openai_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "647d06a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = loader.load_llm() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "69acae4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with get_openai_callback() as cb:\n",
    "#     result = llm.invoke(\"Tell me a joke\")\n",
    "#     print(cb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# from datetime import datetime\n",
    "# from zoneinfo import ZoneInfo\n",
    "# import uuid\n",
    "\n",
    "# def generate_session_id(prefix=\"session\"):\n",
    "#     ist = ZoneInfo(\"Asia/Kolkata\")\n",
    "#     return f\"{prefix}_{datetime.now(ist).strftime('%Y%m%d_%H%M%S')}_{uuid.uuid4().hex[:8]}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "303a57cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_session_id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69428f09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Documentportal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
